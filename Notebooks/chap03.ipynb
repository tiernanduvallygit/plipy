{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the Syntax guide You"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO: fix the syntax inconsistencies for Exp1 - currently stmt_list has a nullable prefix -->\n",
    "\n",
    "\n",
    "<!--\n",
    "\\index{syntax directed language processing}\n",
    "-->\n",
    "\n",
    "Now that we have an understanding of what parsing entails we can build our first interpreters and simple translators.\n",
    "For a certain class of languages we can do our processing as soon as we recognize syntactic structures, that means\n",
    "we can do our processing right in the embedded actions of a grammar.\n",
    "This is called *syntax directed language processing*.\n",
    "We start this chapter by looking at a syntax directed interpreter for Exp1 based on a hand-coded recursive descent parser.\n",
    "We then implement the same interpreter by replacing the hand-coded parser with a machine generated LR(1) parser taking advantage of the embedded actions Ply provides.\n",
    "The last example we look at is a pretty printer for Exp1.  Pretty printers are examples of simple translators.  Here we implement the pretty printer in a syntax directed manner based on the embedded rules in the parser generated by Ply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let the notebook access the code folder\n",
    "import sys\n",
    "sys.path.insert(1,\"code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Syntax-Directed Interpretation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "\\index{interpreter}\n",
    "\\index{interpretation}\n",
    "\\index{interpretation!algebraic terms}\n",
    "\\index{interpretation!assignment statement}\n",
    "\\index{interpretation!syntax-directed}\n",
    "\\index{syntax-directed interpretation}\n",
    "-->\n",
    "\n",
    "According to our classification of language processors in Chapter 1 an interpreter reads a program and executes the program\n",
    "directly (see Chapter 1 Figure 6).\n",
    "We accomplish this by interpreting the syntactic structures as soon as we parse them.\n",
    "This is called *syntax-directed interpretation* where we execute the semantic rules of the language as soon as we recognize\n",
    "the corresponding syntactic structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What exactly do we mean by interpretation?\n",
    "In order to get a better idea of what interpretation is we turn to a language that you are very familiar with: algebra.\n",
    "Consider the algebraic expression,\n",
    "```\n",
    "x = 3\n",
    "```\n",
    "We interpret this expression by first interpreting the symbol `3` as the mathematical value three, we then interpret the symbol\n",
    "`x` as a variable, and because the variable appears to the left of the symbol `=`  we assign the value three to the variable `x`.\n",
    "Now consider the term,\n",
    "```\n",
    "y = 2 + x\n",
    "```\n",
    "In order to interpret this term we first figure out what value is assigned to the variable `x`, we then interpret the symbol `2` as the mathematical\n",
    "value two, and finally we compute the value of the right term by interpreting the `+` symbol as addition computing\n",
    "the value five (if we assume that `x` has the value three from the previous example).  In order to complete the interpretation of this algebraic term we again interpret\n",
    "the `=` as the assignment of the value five to the variable `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "\\index{interpretation!syntax directed}\n",
    "\\index{syntax-direct interpretation}\n",
    "-->\n",
    "\n",
    "One thing you probably noticed at this point is that the interpretation of algebraic terms is *bottom-up*, that is, it starts with the operands\n",
    "that are immediately computable, such as constant symbols or variables,  and works its way up to the top-level operator which in this case is the assignment operator.\n",
    "\n",
    ">This approach to interpretation is called syntax-directed interpretation because the interpretation is guided by the syntactic structure of the terms.\n",
    "\n",
    "We often think of this interpretation as semantics because the interpretation provides a behavioral view of the term or program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Interpreter for Exp1 using a Recursive Descent Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Interpretation of Exp1 Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recall the syntax of our Exp1 language:\n",
    "```\n",
    "prog : stmt_list \n",
    "\n",
    "stmt_list : stmt_list stmt\n",
    "          | empty\n",
    "\n",
    "stmt : PRINT exp ';'\n",
    "     | STORE var exp ';'\n",
    "\n",
    "exp : '+' exp exp\n",
    "    | '-' exp exp\n",
    "    | '(' exp ')'\n",
    "    | var\n",
    "    | num\n",
    "\t\n",
    "var : NAME \n",
    "num : NUMBER\n",
    "```\n",
    "It is the language of pre-fix expressions and has two statements.  One to print values of expressions to the terminal and the other to store the value of an expression in a variable.\n",
    "In order to see what syntax-directed interpretation looks like for our Exp1 language let us start with the parse tree for the program,\n",
    "```\n",
    "store y + 2 x ;\n",
    "```\n",
    "Figure 1 shows the parse tree for this program.  It is clear from the structure of the tree that in order to compute a value to store into variable `y` we would have to interpret the tree starting at the right side leaves and then keep interpreting the operators and computing the values along the tree branches in the direction of the red arrows.  One way to visualize syntax directed interpretation is that values percolate from the tree leaves up to the root. In our case, once interpretation reaches the root of the parse tree the value computed thus far is stored in the variable `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<center>\n",
    "<img src=\"figures/chap03/1/figure/Slide1.jpg\" alt=\"\">\n",
    "Fig 1. Interpreting the parse tree for the program `store y + 2 x ;`.\n",
    "</center>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax Directed Interpretation of Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it turns out that we can achieve the same interpretation behavior that we showed above in a parser without having to construct an explicit parse\n",
    "tree.\n",
    "Consider the non-terminal `exp` defined in\n",
    "the Exp1 grammar as,\n",
    "```\n",
    "exp : '+' exp exp\n",
    "    | '-' exp exp\n",
    "    | '(' exp ')'\n",
    "    | var\n",
    "    | num\n",
    "\n",
    "```\n",
    "Here we look at a hand-built recursive descent parser for this non-terminal.\n",
    "In order to enable syntax directed interpretation of expressions all we have to do is \n",
    "allow return values from the parsing functions.\n",
    "\n",
    "The recursive descent parsing function for expressions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s exp code/exp1_rinterp\n",
    "def exp():\n",
    "    tok = token_stream.pointer()\n",
    "    \n",
    "    if tok.type == '+':\n",
    "        token_stream.next() # match '+'\n",
    "        return exp() + exp()\n",
    "    \n",
    "    elif tok.type == '-':\n",
    "        token_stream.next() # match '-'\n",
    "        return exp() - exp()\n",
    "    \n",
    "    elif tok.type == '(':\n",
    "        token_stream.next() # match '('\n",
    "        val = exp()\n",
    "        token_stream.next() # match ')'\n",
    "        return val\n",
    "    \n",
    "    elif tok.type == 'NAME':\n",
    "        return var()\n",
    "    \n",
    "    elif tok.type == 'NUMBER':\n",
    "        return num()\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError('unexpected symbol {} while parsing'.format(tok.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that the function call sequence representing the non-terminals of the grammar implicitly build a parse tree.  Consider parsing the sub-expression `+ 1 2` that appears in the parse tree in Figure 1 with our\n",
    "`exp()` funtion.  It not difficult to see that the pattern of function calls during parsing match exactly the non-terminals in\n",
    "the parse tree (try tracing the function calls for that expression!).  Furthermore, the return values of the parsing \n",
    "function percolate the values from the leaves of the implicit parse tree up in such a way that the function call to `exp()` in order to parse `+ 1 2` will return the value three.\n",
    "\n",
    "A closer look at the parsing function `exp()` itself.  For the tokens `+` and `-` we see two recursive function calls itself and then given the respective returned values the appropriate arithmetic operation in order to compute the return value, that is, at this point we take the two values that propagated up from the subexpressions, add or subtract them as appropriate, and return the newly computed value. \n",
    "\n",
    "Something very similar happens with the token `(`.  Here we simply return the value of the parenthesized expression.\n",
    "\n",
    "When we encounter variables and numbers in the expression the appropriate parsing functions are called.\n",
    "It turns out that both of those function represent the termination cases for the recursion and provide values for the leaves.  The function `num()` simply returns the value of the number encountered and the function `var()` returns the value associated with the variable name.\n",
    "\n",
    "In short, the function `exp()` represents a recursive function that will recurse while parsing expressions until it\n",
    "finds either a variable to parse with `var()` or a number to parse with `num()`.\n",
    "At that point recursion stops and starts to unwind percolating values up the implicit parse tree.\n",
    "In this way we see computed values percolating up from the leaves to the root of the tree where they can then be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Syntax Directed Interpretation of Variables and Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the parsing functions for variables and numbers.  Notice that the `var()` function looks up the value associated with the variable name in a symbol table.   We made a design choice that if the variable has not been previously initialized we return the value zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s var code/exp1_rinterp\n",
    "def var():\n",
    "    tok = token_stream.pointer()\n",
    "    \n",
    "    if tok.type == 'NAME':\n",
    "        token_stream.next()\n",
    "        return symbol_table.get(tok.value, 0) # return 0 if not found\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError('unexpected symbol {} while parsing'.format(tok.value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s num code/exp1_rinterp\n",
    "def num():\n",
    "    tok = token_stream.pointer()\n",
    "    \n",
    "    if tok.type == 'NUMBER':\n",
    "        token_stream.next()\n",
    "        return tok.value\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError('unexpected symbol {} while parsing'.format(tok.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting an Expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run those functions we need set up our lexical analysis, token stream, and symbol table.    For our lexical analysis we use the lexer for Exp1 from Chapter 2, `exp1_lex.lexer`.  The class `TokenStream` converts a character stream into a token stream using the given lexical analyzer.  Our symbol table is a dictionary in order to associate names with values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp1_lex import lexer\n",
    "from grammar_stuff import TokenStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_table = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_stream = \"+ 1 x0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a little program that illustrates how our token stream works.  The program reads the tokens from the token stream one by one and prints out the token name together with the token value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: name=+ value=+\n",
      "Token: name=NUMBER value=1\n",
      "Token: name=NAME value=x0\n"
     ]
    }
   ],
   "source": [
    "while not token_stream.end_of_file():\n",
    "    tok = token_stream.pointer()\n",
    "    print(\"Token: name={} value={}\".format(tok.type, tok.value))\n",
    "    token_stream.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our token stream works nicely. Now, let's put this to use for parsing and evaluating Exp1 expressions using our recursive descent parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_stream = \"+ 1 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Given an input stream `\"+ 1 2\"` a call to the  `exp()` parsing function returns the value three, as we would expect from our previous discussion.\n",
    "\n",
    "Let's try this on something a bit more complicated,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_stream = \"(- (+ 1 2) 1)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(exp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntax Directed Interpretation of Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get back to our example above that stores a value in a variable, recall the grammar snippet for \n",
    "the non-terminal `stmt` in Exp1,\n",
    "```\n",
    "stmt : PRINT exp ';'\n",
    "     | STORE var exp ';'\n",
    "```\n",
    "The corresponding parsing function looks like this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s stmt code/exp1_rinterp\n",
    "def stmt():\n",
    "    tok = token_stream.pointer()\n",
    "    \n",
    "    if tok.type == 'PRINT':\n",
    "        token_stream.next() # match PRINT\n",
    "        print(\"> {}\".format(exp()))\n",
    "        token_stream.next() # match ;\n",
    "        return None\n",
    "    \n",
    "    elif tok.type == 'STORE':\n",
    "        token_stream.next() # match STORE\n",
    "        name = lvar() # not var()!\n",
    "        val = exp()\n",
    "        symbol_table[name] = val\n",
    "        token_stream.next() # match ;\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError('unexpected symbol {} while parsing'.format(tok.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to notice is that in Exp1 statements themselves do not compute any values and\n",
    "therefore the corresponding parsing function does not return any values.\n",
    "Looking at the function itself we see that in the case of a `PRINT` statement we compute the value of the expression\n",
    "while parsing it and then write that value to the output.\n",
    "In terms of the `STORE` statement we have to be careful with lvalues and rvalues of variables.  Computing rvalues of\n",
    "variables is straight forward as we saw in the `var()` function.  It is simply a matter of looking up the corresponding value in a symbol table.  In a store the name of the variable acts like an lvalue in the sense that it serves as a handle for a location to update.  In our case, the name of the variable is the key into a dictionary\n",
    "and as you see in the `stmt()` function we use that key to update the variable in the symbol table.\n",
    "So the `lvar()` function returns the name of the variable whereas the `var()` function returns the value associated with a variable - lvalue *vs.* rvalue.\n",
    "\n",
    "Here is the definition of the `lvar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s lvar code/exp1_rinterp\n",
    "def lvar():\n",
    "    tok = token_stream.pointer()\n",
    "    \n",
    "    if tok.type == 'NAME':\n",
    "        token_stream.next()\n",
    "        return tok.value # return var name\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError('unexpected symbol {} while parsing'.format(tok.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting Statements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our example, we want to interpret the statement `store y + 2 x ;`.  We need to set up our input and token streams appropriately and reinitialize our symbol table,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_stream = \"store y + 2 x ;\"\n",
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_table = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y': 2}\n"
     ]
    }
   ],
   "source": [
    "print(symbol_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The contents of the symbol table is exactly what we had expected given that the default value for the variable `x` is zero since nothing had been assigned to it.  In order to change that we preload the symbol table with a value for `x`\n",
    "and then set up the input and token streams accordingly,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_table = {'x':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_stream = \"store y + 2 x ;\"\n",
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 3, 'y': 5}\n"
     ]
    }
   ],
   "source": [
    "print(symbol_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "\\index{rvalue}\n",
    "\\index{lvalue}\n",
    "\\index{symbol table}\n",
    "-->\n",
    "\n",
    "<!-- This paragraph makes no sense here...\n",
    "Just as in the program from the previous chapter where we tried to find all the variable references were not variable definitions in an Exp0 program\n",
    "we have to be careful with the interpretation of Exp1 programs and distinguish lvalues and rvalues.\n",
    "If a variable appears as an lvalue (that is it appears as the first argument to the STORE statement) then we assign a value to it and\n",
    "if a variable appears as an rvalue (that is it appears in the expression of the STORE statement) then we just look up the corresponding \n",
    "value for the variable.\n",
    "Value updates and lookups are usually accomplished with the help of a symbol table. \n",
    "Exp1 is simple enough that a simple dictionary like table as a way to associate variable names with values suffices.\n",
    "-->\n",
    "\n",
    "The following video shows an animation of the syntax directed interpretation of our Exp1 program:\n",
    "\n",
    "<!-- videos/chap02/q7/figure.mov -->\n",
    "\n",
    "<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=jmE_9zOfp1g\" target=\"_blank\">\n",
    "<img style='border:1px solid #000000' src=\"movie.jpg\" width=\"120\" height=\"90\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Statement Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than preloading the symbol table with a value for `x` we can  initialize `x` through a `store` statement and we can print out the value of `y` with an Exp1 `print` statement after `y` has been updated.  Adding statment lists to our parser will allow us to do that.  Recall the grammar snippet that specifies statement lists,\n",
    "```\n",
    "stmt_list : stmt_list stmt\n",
    "          | empty\n",
    "\n",
    "```\n",
    "The empty rule makes it difficult to convert the grammar snippet into\n",
    "a recursive descent parser function.\n",
    "However, we can rewrite these rules borrowing some notation from regular expressions,\n",
    "```\n",
    "stmt_list : stmt*\n",
    "```\n",
    "meaning that a statement list consists of zero or more statements.  This allows us to construct a parser function for `stmt_list`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s stmt_list code/exp1_rinterp\n",
    "def stmt_list():\n",
    "    while not token_stream.end_of_file():\n",
    "        stmt()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test this new function we need to reinitialize our symbol table and set up the streams,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbol_table = dict()\n",
    "\n",
    "input_stream = \\\n",
    "'''\n",
    "store x 3; \n",
    "store y + 2 x; \n",
    "print y;\n",
    "'''\n",
    "\n",
    "token_stream = TokenStream(lexer, input_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 5\n"
     ]
    }
   ],
   "source": [
    "stmt_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a fully functioning interpreter for our Exp1 language.  The interpreter is syntax directed because the values are being computed and passed along as we parse the source program.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Toplevel Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a more polished implementation of the interpreter we can add a toplevel driver function,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load -s exp1_rinterp code/exp1_rinterp\n",
    "def exp1_rinterp(input_stream = None):\n",
    "    'driver for our recursive descent Exp1 interpreter.'\n",
    "    \n",
    "    global token_stream\n",
    "    global symbol_table\n",
    "    \n",
    "    if not input_stream:\n",
    "        input_stream = input(\"exp1 > \")\n",
    "    \n",
    "    token_stream = TokenStream(lexer, input_stream)\n",
    "    symbol_table = dict()\n",
    "    \n",
    "    stmt_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 3\n"
     ]
    }
   ],
   "source": [
    "exp1_rinterp(\"store x 1; store y 2; print + x y;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additional feature to consider is to read program files rather than reading programs from strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Interpreter for Exp1 using an LR(1) Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<!-- TODO: rename _rinterp to _rdinterp -->\n",
    "\n",
    "Now that we have a good handle on what syntax directed interpretation entails let us implement our Exp1 interpreter using an LR(1) parser generated by Ply.\n",
    "\n",
    "Recall our Ply grammar for Exp1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# %load code/exp1_gram.py\n",
    "from ply import yacc\n",
    "from exp1_lex import tokens, lexer\n",
    "\n",
    "def p_grammar(_):\n",
    "    \"\"\"\n",
    "    prog : stmt_list\n",
    "    \n",
    "    stmt_list : stmt stmt_list\n",
    "              | empty\n",
    "              \n",
    "    stmt : PRINT exp ';'\n",
    "         | STORE var exp ';'\n",
    "         \n",
    "    exp : '+' exp exp\n",
    "        | '-' exp exp\n",
    "        | '(' exp ')'\n",
    "        | var\n",
    "        | num\n",
    "        \n",
    "    var : NAME\n",
    "        \n",
    "    num : NUMBER\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def p_empty(p):\n",
    "    'empty :'\n",
    "    pass\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "parser = yacc.yacc()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step twoards building an interpreter with this grammar is to break all the grammar rules out into individual functions so that we can embed actions with the grammar rules.\n",
    "The actions are python code that are able to access individual parts of the rules.\n",
    "In particular, we take advantage of the variable `p` which the parser maintains.\n",
    "\n",
    "The variable `p` that gets passed into each of the parsing functions is an array indexed by the tokens and non-terminals\n",
    "appearing in a grammar rule.  Consider the rule,\n",
    "```\n",
    "exp : '+' exp exp\n",
    " 0     1   2   3\n",
    "```\n",
    "We have written the index of `p` underneath each rule component.\n",
    "Here, the value of the `+` token can be accessed with `p[1]`.\n",
    "The value of the first expression after the plus sign can be accessed with `p[2]` and the value of the second expression can be accessed with `p[3]`.\n",
    "Now, recall that LR parsers run grammar rules backwards.\n",
    "So in this case the right side of the rule, `'+' exp exp`, will be replaced by `exp` on the stack.\n",
    "Just before this happens we can assign a value to the resulting `exp` as follows,\n",
    "```\n",
    "p[0] = p[2] + p[3]\n",
    "```\n",
    "That is, just before the right side of the rule is replaced with the left side we pull the values of the expressions\n",
    "on the right side, use them to compute the value of the resulting expression, and then assign that value to the \n",
    "resulting expression with the index of zero, `p[0]`.  In essence we emulated here exactly the same computations we performed in our recursive descent parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Exp1 Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our Ply grammar with the embedded actions that make extensive use of the `p` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# %load code/exp1_lrinterp_gram.py\n",
    "from ply import yacc\n",
    "from exp1_lex import tokens, lexer\n",
    "\n",
    "symbol_table = dict()\n",
    "\n",
    "def p_prog(_):\n",
    "    \"prog : stmt_list\"\n",
    "    pass\n",
    "\n",
    "def p_stmt_list(_):\n",
    "    \"\"\"\n",
    "    stmt_list : stmt stmt_list\n",
    "              | empty\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def p_print_stmt(p):\n",
    "    \"stmt : PRINT exp ';'\"\n",
    "    print(\"> {}\".format(p[2]))\n",
    "    \n",
    "def p_store_stmt(p):\n",
    "    \"stmt : STORE NAME exp ';'\"\n",
    "    symbol_table[p[2]] = p[3]\n",
    "\n",
    "def p_plus_exp(p):\n",
    "    \"\"\"\n",
    "    exp : '+' exp exp\n",
    "    \"\"\"\n",
    "    p[0] = p[2] + p[3]\n",
    "\n",
    "def p_minus_exp(p):\n",
    "    \"\"\"\n",
    "    exp : '-' exp exp\n",
    "    \"\"\"\n",
    "    p[0] = p[2] - p[3]\n",
    "\n",
    "def p_paren_exp(p):\n",
    "    \"\"\"\n",
    "    exp : '(' exp ')'\n",
    "    \"\"\"\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_var_exp(p):\n",
    "    \"exp : var\"\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_num_exp(p):\n",
    "    \"exp : num\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_var(p):\n",
    "    \"var : NAME\"\n",
    "    p[0] = symbol_table.get(p[1], 0)\n",
    "\n",
    "def p_num(p):\n",
    "    \"num : NUMBER\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_empty(p):\n",
    "    \"empty :\"\n",
    "    pass\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "parser = yacc.yacc(debug=False, tabmodule='exp1parsetab')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the more interesting functions to look at in this grammar is the `p_store_stmt` function where the value of the expression `p[3]` is used\n",
    "to update the symbol table at key `p[2]`.\n",
    "Another interesting function is the `p_arith_exp` function where we use the value of the first token on the left side of the rule, `p[1]`, to figure\n",
    "out what arithmetic operation we need to perform on the expression values `p[2]` and `p[3]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our LR(1) Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now import the parser from that grammar to test whether our interpreter actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\n"
     ]
    }
   ],
   "source": [
    "from exp1_lrinterp_gram import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 11\n"
     ]
    }
   ],
   "source": [
    "parser.parse(input=\"store x 1; print + x 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, that worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding a Toplevel Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the case of our recursive descent parser, we can  provide a toplevel driver function to provide a more polished interface to our interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load -s exp1_lrinterp code/exp1_lrinterp\n",
    "def exp1_lrinterp(input_stream = None):\n",
    "    'A driver for our LR Exp1 interpreter.'\n",
    "    \n",
    "    if not input_stream:\n",
    "        input_stream = input(\"exp1 > \")\n",
    "    \n",
    "    parser.parse(input_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 3\n"
     ]
    }
   ],
   "source": [
    "exp1_lrinterp(\"store x 1; store y 2; print + x y;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Take on Syntax-Directed Processing: A Pretty Printer for Exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "\\index{syntax directed translation}\n",
    "\\index{translation!syntax directed}\n",
    "-->\n",
    "\n",
    "Syntax directed language processing does not only apply to interpretation.  We can also use syntax directed techniques to build\n",
    "simple translators.\n",
    "A pretty printer for our Exp1 language is a good example to look at.\n",
    "As you might know, pretty printers are programs that read the source of a program written in some programming language\n",
    "and then generate code in the same language but formatted nicely so that the program is easy to read.\n",
    "This is a great example of a simple translator shown in Figure 8 Chapter 1 except in our case it is not necessary\n",
    "to construct an IR because we will use syntax directed translation.\n",
    "Our pretty printer accomplishes two things: \n",
    "\n",
    "1. It will put each statement on its own line.  \n",
    "\n",
    "2. Expressions will be written in Lisp like syntax.  In Lisp, each operation is embedded in a pair of parentheses.  For example, to add two numbers in Lisp we write the following expression,\n",
    "```\n",
    "(+ 2 3)\n",
    "```\n",
    "This also means we  get rid of unnecessary parentheses.  For example, the expression `((+ (2) (3)))` will be rewritten as above.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pretty Printer Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is our Exp1 grammar extended with the embedded actions that allow us to generate the pretty printed code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "# %load code/exp1_pp_gram.py\n",
    "from ply import yacc\n",
    "from exp1_lex import tokens, lexer\n",
    "\n",
    "def p_prog(p):\n",
    "    \"prog : stmt_list\"\n",
    "    print(p[1])\n",
    "\n",
    "def p_stmt_list(p):\n",
    "    \"stmt_list : stmt stmt_list\"\n",
    "    p[0] = p[1] + p[2]\n",
    "\n",
    "def p_stmt_list_empty(p):\n",
    "    \"stmt_list : empty\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_print_stmt(p):\n",
    "    \"stmt : PRINT exp ';'\"\n",
    "    p[0] = 'print' + p[2] +';\\n'\n",
    "\n",
    "def p_store_stmt(p):\n",
    "    \"stmt : STORE NAME exp ';'\"\n",
    "    p[0] = 'store ' + p[2] + p[3] +';\\n'\n",
    "\n",
    "def p_arith_exp(p):\n",
    "    \"\"\"\n",
    "    exp : '+' exp exp\n",
    "        | '-' exp exp\n",
    "        | '(' exp ')'\n",
    "    \"\"\"\n",
    "    if p[1] == '+':\n",
    "        p[0] = ' (+' + p[2] + p[3] + ')'\n",
    "    elif p[1] == '-':\n",
    "        p[0] = ' (-' + p[2] + p[3] + ')'\n",
    "    elif p[1] == '(':\n",
    "        p[0] = p[2]\n",
    "    else:\n",
    "        raise SyntaxError(\"parsing weirdness in expressions: {} !\".format(p[1]))\n",
    "\n",
    "def p_var_exp(p):\n",
    "    \"exp : var\"\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_num_exp(p):\n",
    "    \"exp : num\"\n",
    "    p[0] = p[1]\n",
    "\n",
    "def p_var(p):\n",
    "    \"var : NAME\"\n",
    "    p[0] = ' ' + p[1]\n",
    "\n",
    "def p_num(p):\n",
    "    \"num : NUMBER\"\n",
    "    p[0] = ' ' + str(p[1])\n",
    "\n",
    "def p_empty(p):\n",
    "    \"empty :\"\n",
    "    p[0] = ''\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "parser = yacc.yacc()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea in this syntax directed approach to our pretty printer is that we will assemble a string that contains the \n",
    "pretty printed program while we are parsing the source program.  In order to see this the best place to start are the rules for variables and numbers,\n",
    "```Python\n",
    "def p_var(p):\n",
    "    \"var : NAME\"\n",
    "    p[0] = ' ' + p[1]\n",
    "\n",
    "def p_num(p):\n",
    "    \"num : NUMBER\"\n",
    "    p[0] = ' ' + str(p[1])\n",
    "```\n",
    "Let's take a look at the rule for variables.  Recall that the value of `p[1]` is the value of the corresponding\n",
    "token in the rule, in this case the token `NAME`.  The value, in this case, being the actual variable name as it \n",
    "appears in the source program.  The embedded action for this grammar rule assembles the string `' ' + p[1]`,\n",
    "that is a space followed by the name of the variable, and assigns this to the non-terminal `var`.\n",
    "The space is necessary for formatting reasons so that names and symbols in the pretty printed program are separated by\n",
    "white space.\n",
    "\n",
    "Something very similar happens in the rule for numbers.  Here we generate the string `' ' + p[1]` where `p[1]` \n",
    "has the numeric value of the token `NUMBER`.  The generated string is then assigned to the non-terminal `num`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know what the leaves of an expression generate for pretty printed strings we will take a look\n",
    "at the rules for expressions. Let's start at the expression rules for variables and numbers, \n",
    "```Python\n",
    "\n",
    "def p_var_exp(p):\n",
    "    \"exp : var\"\n",
    "    p[0] = p[1]\n",
    "    \n",
    "def p_num_exp(p):\n",
    "    \"exp : num\"\n",
    "    p[0] = p[1]\n",
    "```\n",
    "In both cases the embedded actions just copy the string value from the non-terminals `var` and `num`, respectively,\n",
    "and assign it to the non-terminal `exp` on the left side of the grammar rule.\n",
    "\n",
    "We are now ready to look at the rules for the other expressions which are the addition and subtraction\n",
    "operations and the parenthesized expressions. \n",
    "```Python\n",
    "def p_arith_exp(p):\n",
    "    \"\"\"\n",
    "    exp : '+' exp exp\n",
    "        | '-' exp exp\n",
    "        | '(' exp ')'\n",
    "    \"\"\"\n",
    "    if p[1] == '+':\n",
    "        p[0] = ' (+' + p[2] + p[3] + ')'\n",
    "    elif p[1] == '-':\n",
    "        p[0] = ' (-' + p[2] + p[3] + ')'\n",
    "    elif p[1] == '(':\n",
    "        p[0] = p[2]\n",
    "    else:\n",
    "        raise SyntaxError(\"parsing weirdness in expressions: {} !\".format(p[1]))\n",
    "```\n",
    "The embedded action for the addition operation computes a string that contains the parenthesized addition operator\n",
    "together with its arguments from the two expressions, `p[2]` and `p[3]`.  If the souce program contained the \n",
    "expression `+ x 1` then the embedded action for the addition operator will compute the string `' (+ x 1)'`.\n",
    "Similarly for the subtraction operator.\n",
    "\n",
    "Parentheses from the source program are ignored.  The rule for parenthesized expressions just copies\n",
    "the string from the expression on the right of the rule to the left of the rule ignoring the parentheses.\n",
    "\n",
    "The embedded actions for print and store statements should now be fairly obvious.  They each assemble nicely formatted\n",
    "strings for the respective commands.  Notice the `\\n` character at the end of the strings which means that each \n",
    "print and store command will be on its own line as required.\n",
    "\n",
    "Finally, the embedded actions for statement lists generate one long string for the pretty printed program.\n",
    "The embedded action for the non-terminal `prog`, our start symbol, print the string containing the pretty printed\n",
    "program to the terminal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Pretty Printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating LALR tables\n"
     ]
    }
   ],
   "source": [
    "from exp1_pp_gram import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store x 1;\n",
      "store y 2;\n",
      "print (+ x y);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser.parse(\"store x 1; store y 2; print + x y;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pretty printer works as we wanted it to.  Each statement is on its own line and expressions written in Lisp syntax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to pull this all together into a nice tidy program we can add a toplevel driver as we did for the interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load code/exp1_pp.py\n",
    "from exp1_pp_gram import parser\n",
    "\n",
    "def exp1_pp(input_stream = None):\n",
    "    'A driver for our Exp1 pretty printer.'\n",
    "    \n",
    "    if not input_stream:\n",
    "        input_stream = input(\"exp1 > \")\n",
    "    \n",
    "    parser.parse(input_stream)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store x 1;\n",
      "store y 2;\n",
      "print (+ x y);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp1_pp(\"store x 1; store y 2; print + x y;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a certain class of programming languages we can construct syntax directed processors.  That is, we can construct processors that can execute some semantic action when relevant syntactic structures have been recognized.  We show that Exp1 can be processed in a syntax directed manner by first constructing an interpreter based on a recursive descent parser and then by constructing an interpreter based on an LR(1) parser generated by Ply.\n",
    "Syntax directed techniques can also be applied to translators.  We showed this by constructing a pretty printer for Exp1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The earliest reference to syntax directed translation we found is (Irons, 1961). A more modern take on syntax directed techniques can be found in (Aho *et al*, 1986).\n",
    "\n",
    "\n",
    "Irons, E. T. (1961). *A syntax directed compiler for ALGOL 60*. Communications of the ACM, 4(1), 51-55.\n",
    "\n",
    "Aho, A. V., Sethi, R., & Ullman, J. D. (1986). *Compilers, Principles, Techniques* . Boston: Addison-Wesley.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO: More exercises -->\n",
    "\n",
    "1. (project) Use the code for the Exp1 interpreter from above and extend the language with multiplication and integer division.  Demonstrate that your interpreter works by running it on some telling examples.\n",
    " \n",
    "2. Write some additional programs in Exp1 and run an interpreter on them.\n",
    "```Python\n",
    "from exp1_lrinterp_gram import parser\n",
    "parser.parse(\"store x 1; store y 2; print + x y;\")\n",
    "```\n",
    "\n",
    "3. (project) Design a language and construct a syntax directed interpreter for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
